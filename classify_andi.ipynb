{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses, metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "#from keras.models import load_model\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "#from data_split import data_split\n",
    "from utils import data_norm, data_reshape, many_net_uhd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example file we saw how to use the networks for trajectories of equal length. Now let's see how to use them for trajectories of different lengths as the ones provided in the AnDi Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the data from the AnDi Challenge at https://andi-app.herokuapp.com/andi_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trajs_from_files = csv.reader(open('challenge_for_scoring/task2.txt','r'), delimiter=';', \n",
    "                                        lineterminator='\\n',quoting=csv.QUOTE_NONNUMERIC)\n",
    "validation = [[],[],[]]\n",
    "for trajs in enumerate(trajs_from_files):\n",
    "    validation[int(trajs[1][0])-1].append(trajs[1][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the networks used for classification in 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_class_1d = [25, 65, 125, 225, 425, 825]\n",
    "\n",
    "meta_model_class_1d = []\n",
    "for i in centers_class_1d: \n",
    "    m = load_model('nets/classification_nets/1d/classification_1D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_class_1d.append(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the classification networks is an array giving the probability that the trajectory belongs to a model class. The classes, as in the AnDi challenge are [attm,ctrw,fbm,lw,sbm]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block size used for the different trajectory lengths\n",
    "for n in meta_model_class_1d:\n",
    "        print(n.layers[0].input_shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the 1d classification nets to a set of trajectories of varying length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_set = validation[0][:10000]\n",
    "tot_tt=len(traj_set)\n",
    "count=0\n",
    "pred_class_1d = []\n",
    "for traj in traj_set:\n",
    "    count=count+1\n",
    "    aa = np.asarray(traj).reshape(1,-1)\n",
    "    pr = many_net_uhd(nets = meta_model_class_1d, traj_set = aa, centers = centers_class_1d ,dim = 1, task =1)\n",
    "   # print(pr)\n",
    "    pred_class_1d.append(pr.flatten())\n",
    "    print('traj',count,'/',tot_tt,end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions need to be reshaped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_1d = np.asarray(pred_class_1d).reshape(-1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_class_2d = [25, 65, 125, 225, 425]\n",
    "meta_model_class_2d = []\n",
    "for i in centers_class_2d: \n",
    "    m = load_model('nets/classification_nets/2d/classification_2D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_class_2d.append(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_set = validation[1][:10000]\n",
    "tot_tt=len(traj_set)\n",
    "count=0\n",
    "pred_class_2d = []\n",
    "for traj in traj_set:\n",
    "    count=count+1\n",
    "    aa = np.asarray(traj).reshape(1,-1)\n",
    "    pr = many_net_uhd(nets = meta_model_class_2d, traj_set = aa, centers = centers_class_2d ,dim = 2, task =2)\n",
    "   # print(pr)\n",
    "    pred_class_2d.append(pr.flatten())\n",
    "    print('traj',count,'/',tot_tt,end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_2d = np.asarray(pred_class_2d).reshape(-1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_class_3d = [25, 65, 125, 225, 425]\n",
    "meta_model_class_3d = []\n",
    "for i in centers_class_3d: \n",
    "    m = load_model('nets/classification_nets/3d/classification_3D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_class_3d.append(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_set = validation[2]\n",
    "tot_tt=len(traj_set)\n",
    "count=0\n",
    "pred_class_3d = []\n",
    "for traj in traj_set:\n",
    "    count=count+1\n",
    "    aa = np.asarray(traj).reshape(1,-1)\n",
    "    pr = many_net_uhd(nets = meta_model_class_3d, traj_set = aa, centers = centers_class_3d ,dim = 3, task =2)\n",
    "   # print(pr)\n",
    "    pred_class_3d.append(pr.flatten())\n",
    "    print('traj',count,'/',tot_tt,end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_3d = np.asarray(pred_class_3d).reshape(-1,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
