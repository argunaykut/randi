{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils import data_norm, data_reshape, many_net_uhd, my_atan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating trajectories to test the data. 3 trajectories for each dimension of inference and classification tasks. This requires the AnDi package, downloadable at https://github.com/AnDiChallenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD = andi.andi_datasets()\n",
    "traj_length = 200\n",
    "\n",
    "X1, Y1, X2, Y2, X3, Y3 = AD.andi_dataset(N = 10, tasks = [1,2,3], dimensions = [1,2,3],\n",
    "                                        min_T = traj_length, max_T = traj_length+1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference of 1d trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the inference networks is the inferred anomalous exponent for each trajectory. Trajectories must be of equal length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the networks used for inference in 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_inf_1d = [25, 50, 65, 75, 125, 165, 225, \n",
    "                  325, 425, 525, 625, 725, 825, 925]\n",
    "meta_model_inf_1d = []\n",
    "for i in centers_inf_1d: \n",
    "    m = load_model('nets/inference_nets/1d/inference_1D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_inf_1d.append(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the net trained on trajectories of length 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing the net\n",
    "net = meta_model_inf_1d[5]\n",
    "#finding out the block size used by the chosen net\n",
    "bs = net.layers[0].input_shape[-1]\n",
    "\n",
    "#normalizing the data\n",
    "data = data_norm(X1[0],dim=1,task=1)\n",
    "\n",
    "#reshaping the data\n",
    "data_rs = data_reshape(data,bs=bs,dim=1)\n",
    "\n",
    "#prediction on trajectories of length 200 using a net trained on traj of length 165\n",
    "pred_200_u165 = net.predict(data_rs)\n",
    "print('predicted exponents', pred_200_u165.flatten())\n",
    "print('ground truth', Y1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the net trained on trajectories of length 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing the net\n",
    "net = meta_model_inf_1d[6]\n",
    "#finding out the block size used by the chosen net\n",
    "bs = net.layers[0].input_shape[-1]\n",
    "\n",
    "#normalizing the data\n",
    "data = data_norm(X1[0],dim=1,task=1)\n",
    "\n",
    "#reshaping the data\n",
    "data_rs = data_reshape(data,bs=bs,dim=1)\n",
    "\n",
    "#prediction on trajectories of length 200 using a net trained on traj of length 225\n",
    "pred_200_u225 = net.predict(data_rs)\n",
    "print('predicted exponents', pred_200_u225.flatten())\n",
    "print('ground truth', Y1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the combination of nearest nets, which in this case is 165 and 225 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_200_comb = many_net_uhd(nets = meta_model_inf_1d, traj_set = X1[0], centers = centers_inf_1d ,dim = 1, task =1)\n",
    "print('predicted exponents',pred_200_comb)\n",
    "print('ground truth', Y1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in 2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the classiciation networks is an array giving the probability that the trajectory belongs to a model class. The classes, as in AnDi are [attm,ctrw,fbm,lw,sbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_class_2d = [25, 65, 125, 225, 425]\n",
    "meta_model_class_2d = []\n",
    "for i in centers_class_2d: \n",
    "    m = load_model('nets/classification_nets/2d/classification_2D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_class_2d.append(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing the net\n",
    "net = meta_model_class_2d[2]\n",
    "#finding out the block size used by the chosen net\n",
    "bs = net.layers[0].input_shape[-1]\n",
    "\n",
    "#normalizing the data\n",
    "data = data_norm(X2[1],dim=2,task=2)\n",
    "\n",
    "\n",
    "#reshaping the data\n",
    "\n",
    "data_rs = data_reshape(data,bs=bs,dim=2)\n",
    "#prediction on trajectories of length 200 using a net trained on traj of length 165\n",
    "cla_200_u125 = net.predict(data_rs)\n",
    "print(\"probability of each model class\",'\\n',cla_200_u125)\n",
    "print(\"predicte most likely model\")\n",
    "models = ['attm', 'ctrw', 'fbm', 'lw', 'sbm'] \n",
    "for i in range(len(data)):\n",
    "    print(models[np.argmax(cla_200_u125[i])])\n",
    "print('Ground truth')    \n",
    "for i in range(len(data)):\n",
    "    print(models[int(Y2[1][i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cla_200_comb = many_net_uhd(nets = meta_model_class_2d, traj_set = X2[1], centers = centers_class_2d ,dim = 2, task =2)\n",
    "cla_200_comb = cla_200_comb.reshape(-1,5)\n",
    "print(\"probability of each model class\",'\\n',cla_200_comb)\n",
    "print(\"most likely model\")\n",
    "models = ['attm', 'ctrw', 'fbm', 'lw', 'sbm'] \n",
    "for i in range(len(data)):\n",
    "    print(models[np.argmax(cla_200_comb[i])])\n",
    "print('Ground truth')    \n",
    "for i in range(len(data)):\n",
    "    print(models[int(Y2[1][i])])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation in 3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network to infer the exponents of the two segments and the switching point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_t3d = tf.keras.models.load_model('nets/segmentation_nets/3d/T33D_inf.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network to classify the model of the second segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2_3d = tf.keras.models.load_model('nets/segmentation_nets/3d/T33D_c2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is [a1,a2,sin(2pi*t/T),cos(2pi*t/T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding out the block size used by the chosen net\n",
    "bs = model_a_t3d.layers[0].input_shape[-1]\n",
    "\n",
    "#normalizing the data\n",
    "data = data_norm(X3[2],dim=3,task=3)\n",
    "\n",
    "#reshaping the data\n",
    "data_rs = data_reshape(data,bs=bs,dim=3)\n",
    "\n",
    "#prediction on trajectories of length 200 using a net trained on traj of length 165\n",
    "inf_seg = model_a_t3d.predict(data_rs)\n",
    "pred_t = my_atan(inf_seg[:,2],inf_seg[:,3])*200/(2*np.pi)\n",
    "cl2_3d = class2_3d.predict(data_rs)\n",
    "\n",
    "print('predicted first exponents', inf_seg[:,0])\n",
    "print('ground truth first exponents', Y3[2][:,3])\n",
    "print('predicted second exponents', inf_seg[:,1])\n",
    "print('ground truth second exponents', Y3[2][:,5])\n",
    "print('predicted time and exponents', pred_t)\n",
    "print('ground truth time', Y3[2][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"probability of each model class for second segment\",'\\n',cl2_3d)\n",
    "print(\"most likely model\")\n",
    "models = ['attm', 'ctrw', 'fbm', 'lw', 'sbm'] \n",
    "for i in range(len(data)):\n",
    "    print(models[np.argmax(cl2_3d[i])])\n",
    "print('Ground truth')    \n",
    "for i in range(len(data)):\n",
    "    print(models[int(Y3[2][i,2])])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
