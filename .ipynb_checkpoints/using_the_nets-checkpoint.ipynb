{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils import data_norm, data_reshape, many_net_uhd, my_atan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating trajectories to test the data. 3 trajectories for each dimension of inference and classification tasks. This requires the AnDi package, downloadable at https://github.com/AnDiChallenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) [1, 2, 3] and dimension(s) [1, 2, 3].\n",
      "Generating dataset for dimension 1.\n",
      "Generating dataset for dimension 2.\n",
      "Generating dataset for dimension 3.\n"
     ]
    }
   ],
   "source": [
    "AD = andi.andi_datasets()\n",
    "traj_length = 200\n",
    "\n",
    "X1, Y1, X2, Y2, X3, Y3 = AD.andi_dataset(N = 10, tasks = [1,2,3], dimensions = [1,2,3],\n",
    "                                        min_T = traj_length, max_T = traj_length+1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference of 1d trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the inference networks is the inferred anomalous exponent for each trajectory. Trajectories must be of equal length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the networks used for inference in 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_inf_1d = [25, 50, 65, 75, 125, 165, 225, \n",
    "                  325, 425, 525, 625, 725, 825, 925]      # Length that the neural networks are trained for\n",
    "meta_model_inf_1d = []\n",
    "for i in centers_inf_1d: \n",
    "    m = load_model('nets/inference_nets/1d/inference_1D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_inf_1d.append(m)                          # A list of neural networks that are trained for specific length\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network trained on trajectories of 165 is used to analyze trajectories of length 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted exponents [0.3297272  1.4824448  1.5020162  0.93287134 1.6899136  1.5477296\n",
      " 1.8939477  1.5448136  1.222714   0.18381149]\n",
      "ground truth [0.3, 1.45, 2.0, 1.25, 1.35, 1.3, 1.8, 1.55, 0.65, 0.2]\n"
     ]
    }
   ],
   "source": [
    "#choosing the net\n",
    "net = meta_model_inf_1d[5]                              \n",
    "#finding out the block size used by the chosen net\n",
    "bs = net.layers[0].input_shape[-1]\n",
    "\n",
    "#normalizing the data\n",
    "data = data_norm(X1[0],dim=1,task=1)\n",
    "\n",
    "#reshaping the data\n",
    "data_rs = data_reshape(data,bs=bs,dim=1)\n",
    "\n",
    "#prediction on trajectories of length 200 using a net trained on traj of length 165\n",
    "pred_200_u165 = net.predict(data_rs)\n",
    "print('predicted exponents', pred_200_u165.flatten())\n",
    "print('ground truth', Y1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network trained on trajectories of 225 is used to analyze trajectories of length 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted exponents [0.4293936  1.4391744  1.6014469  0.90228367 1.6145022  1.4664931\n",
      " 1.8764971  1.6154985  1.3431249  0.1748659 ]\n",
      "ground truth [0.3, 1.45, 2.0, 1.25, 1.35, 1.3, 1.8, 1.55, 0.65, 0.2]\n"
     ]
    }
   ],
   "source": [
    "#choosing the net\n",
    "net = meta_model_inf_1d[6]\n",
    "#finding out the block size used by the chosen net\n",
    "bs = net.layers[0].input_shape[-1]\n",
    "\n",
    "#normalizing the data\n",
    "data = data_norm(X1[0],dim=1,task=1)\n",
    "\n",
    "#reshaping the data\n",
    "data_rs = data_reshape(data,bs=bs,dim=1)\n",
    "\n",
    "#prediction on trajectories of length 200 using a net trained on traj of length 225\n",
    "pred_200_u225 = net.predict(data_rs)\n",
    "print('predicted exponents', pred_200_u225.flatten())\n",
    "print('ground truth', Y1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the combination of nearest nets\n",
    "This demonstrates how using the two nearest networks (which in this case is 165 and 225) help to analyze the exponents more accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted exponents [0.3878659  1.4572036  1.5600173  0.9150285  1.6459236  1.5003417\n",
      " 1.8837682  1.5860465  1.2929536  0.17859322]\n",
      "ground truth [0.3, 1.45, 2.0, 1.25, 1.35, 1.3, 1.8, 1.55, 0.65, 0.2]\n"
     ]
    }
   ],
   "source": [
    "pred_200_comb = many_net_uhd(nets = meta_model_inf_1d, traj_set = X1[0], centers = centers_inf_1d ,dim = 1, task =1)\n",
    "print('predicted exponents',pred_200_comb)\n",
    "print('ground truth', Y1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in 2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the classiciation networks is an array giving the probability that the trajectory belongs to a model class. The classes, as in AnDi are [attm,ctrw,fbm,lw,sbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_class_2d = [25, 65, 125, 225, 425]\n",
    "meta_model_class_2d = []\n",
    "for i in centers_class_2d: \n",
    "    m = load_model('nets/classification_nets/2d/classification_2D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_class_2d.append(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network trained on trajectories of 165 is used to analyze trajectories of length 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of each model class \n",
      " [[7.55120896e-11 9.55009682e-12 8.45531556e-09 1.00000000e+00\n",
      "  7.35940753e-11]\n",
      " [4.12690043e-01 1.97531102e-04 3.54377985e-01 4.17918200e-04\n",
      "  2.32316568e-01]\n",
      " [4.75204699e-02 9.51892078e-01 6.10700567e-07 5.86562208e-04\n",
      "  3.66807512e-07]\n",
      " [2.75578916e-01 5.69130898e-05 4.53345060e-01 1.06699485e-03\n",
      "  2.69952208e-01]\n",
      " [5.23142051e-04 8.55310427e-05 9.98525202e-01 2.45737169e-07\n",
      "  8.65959795e-04]\n",
      " [2.16318071e-02 9.93439426e-06 1.26819694e-02 7.47587364e-06\n",
      "  9.65668857e-01]\n",
      " [1.19896204e-10 2.22436826e-11 3.15713677e-08 1.00000000e+00\n",
      "  2.17166406e-11]\n",
      " [9.98183548e-01 1.60190160e-03 5.55786528e-06 1.94007720e-04\n",
      "  1.50409105e-05]\n",
      " [4.80145589e-02 3.98567354e-04 8.80312324e-02 3.31699921e-05\n",
      "  8.63522470e-01]\n",
      " [3.02954833e-03 9.96969521e-01 6.27174686e-08 9.18807757e-07\n",
      "  3.77421685e-08]]\n",
      "predicted most likely model\n",
      "lw\n",
      "attm\n",
      "ctrw\n",
      "fbm\n",
      "fbm\n",
      "sbm\n",
      "lw\n",
      "attm\n",
      "sbm\n",
      "ctrw\n",
      "Ground truth\n",
      "lw\n",
      "attm\n",
      "ctrw\n",
      "fbm\n",
      "fbm\n",
      "sbm\n",
      "lw\n",
      "attm\n",
      "sbm\n",
      "ctrw\n"
     ]
    }
   ],
   "source": [
    "#choosing the net\n",
    "net = meta_model_class_2d[2]\n",
    "#finding out the block size used by the chosen net\n",
    "bs = net.layers[0].input_shape[-1]\n",
    "\n",
    "#normalizing the data\n",
    "data = data_norm(X2[1],dim=2,task=2)\n",
    "\n",
    "\n",
    "#reshaping the data\n",
    "\n",
    "data_rs = data_reshape(data,bs=bs,dim=2)\n",
    "#prediction on trajectories of length 200 using a net trained on traj of length 165\n",
    "cla_200_u125 = net.predict(data_rs)\n",
    "print(\"probability of each model class\",'\\n',cla_200_u125)\n",
    "print(\"predicted most likely model\")\n",
    "models = ['attm', 'ctrw', 'fbm', 'lw', 'sbm'] \n",
    "for i in range(len(data)):\n",
    "    print(models[np.argmax(cla_200_u125[i])])\n",
    "print('Ground truth')    \n",
    "for i in range(len(data)):\n",
    "    print(models[int(Y2[1][i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of each model class \n",
      " [[4.19571461e-11 1.55693045e-11 1.85102422e-08 1.00000000e+00\n",
      "  2.61412159e-11]\n",
      " [3.59516710e-01 5.59711247e-04 4.19125468e-01 1.70295214e-04\n",
      "  2.20627859e-01]\n",
      " [3.69644985e-02 9.62798476e-01 5.25411906e-06 2.29561221e-04\n",
      "  2.13348744e-06]\n",
      " [2.35607415e-01 3.65132262e-04 4.98450071e-01 1.96813699e-03\n",
      "  2.63609260e-01]\n",
      " [2.55438033e-04 1.34457630e-04 9.99267757e-01 1.10629216e-07\n",
      "  3.42214567e-04]\n",
      " [6.39395416e-03 5.90570380e-06 3.69449146e-03 2.11602037e-06\n",
      "  9.89903569e-01]\n",
      " [3.04736722e-11 6.45942111e-12 8.81077078e-09 1.00000000e+00\n",
      "  5.54974296e-12]\n",
      " [9.99222279e-01 6.74419338e-04 1.21888761e-05 7.31877299e-05\n",
      "  1.80117531e-05]\n",
      " [1.99536663e-02 2.01059884e-04 3.78071629e-02 1.58722614e-05\n",
      "  9.42022324e-01]\n",
      " [2.73457030e-03 9.97263551e-01 3.58038989e-07 1.32219566e-06\n",
      "  1.48754381e-07]]\n",
      "most likely model\n",
      "lw\n",
      "fbm\n",
      "ctrw\n",
      "fbm\n",
      "fbm\n",
      "sbm\n",
      "lw\n",
      "attm\n",
      "sbm\n",
      "ctrw\n",
      "Ground truth\n",
      "lw\n",
      "attm\n",
      "ctrw\n",
      "fbm\n",
      "fbm\n",
      "sbm\n",
      "lw\n",
      "attm\n",
      "sbm\n",
      "ctrw\n"
     ]
    }
   ],
   "source": [
    "cla_200_comb = many_net_uhd(nets = meta_model_class_2d, traj_set = X2[1], centers = centers_class_2d ,dim = 2, task =2)\n",
    "cla_200_comb = cla_200_comb.reshape(-1,5)\n",
    "print(\"probability of each model class\",'\\n',cla_200_comb)\n",
    "print(\"most likely model\")\n",
    "models = ['attm', 'ctrw', 'fbm', 'lw', 'sbm'] \n",
    "for i in range(len(data)):\n",
    "    print(models[np.argmax(cla_200_comb[i])])\n",
    "print('Ground truth')    \n",
    "for i in range(len(data)):\n",
    "    print(models[int(Y2[1][i])])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation in 3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network to infer the exponents of the two segments and the switching point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_t3d = load_model('nets/segmentation_nets/3d/T33D_inf.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network to classify the model of the second segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2_3d = load_model('nets/segmentation_nets/3d/T33D_c2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is [a1,a2,sin(2pi*t/T),cos(2pi*t/T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted first exponents [0.5797447  0.6147374  0.3347436  1.230671   0.5097573  1.0161972\n",
      " 0.42441815 0.455482   0.5678468  0.72195107]\n",
      "ground truth first exponents [1.6  0.1  0.15 1.6  1.1  0.65 0.9  0.6  1.4  1.2 ]\n",
      "predicted second exponents [1.829998   1.5415918  0.9014102  1.0125735  0.3182495  1.7972714\n",
      " 1.8258257  0.40838283 1.124426   0.45345384]\n",
      "ground truth second exponents [1.9  1.65 1.15 0.55 0.15 1.85 1.75 0.1  0.7  0.7 ]\n",
      "predicted time and exponents [ 27.36010047  35.14043156 189.22398873 117.51175227  47.88340925\n",
      "   7.48563974  32.20398904 155.44904384 191.9498973  176.26879801]\n",
      "ground truth time [ 36.  35. 192. 120.  50.  13.  32. 156. 179. 177.]\n"
     ]
    }
   ],
   "source": [
    "#finding out the block size used by the chosen net\n",
    "bs = model_a_t3d.layers[0].input_shape[-1]\n",
    "\n",
    "#normalizing the data\n",
    "data = data_norm(X3[2],dim=3,task=3)\n",
    "\n",
    "#reshaping the data\n",
    "data_rs = data_reshape(data,bs=bs,dim=3) \n",
    "\n",
    "#prediction on trajectories of length 200 using a net trained on traj of length 165\n",
    "inf_seg = model_a_t3d.predict(data_rs)\n",
    "pred_t = my_atan(inf_seg[:,2],inf_seg[:,3])*200/(2*np.pi)\n",
    "cl2_3d = class2_3d.predict(data_rs)\n",
    "\n",
    "print('predicted first exponents', inf_seg[:,0])\n",
    "print('ground truth first exponents', Y3[2][:,3])\n",
    "print('predicted second exponents', inf_seg[:,1])\n",
    "print('ground truth second exponents', Y3[2][:,5])\n",
    "print('predicted time and exponents', pred_t)\n",
    "print('ground truth time', Y3[2][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of each model class for second segment \n",
      " [[7.1035953e-05 6.7777168e-05 9.9347335e-01 4.8248051e-03 1.5630369e-03]\n",
      " [5.2410032e-04 1.8390221e-05 8.5001326e-01 8.8109989e-03 1.4063327e-01]\n",
      " [2.8311330e-01 1.2330370e-01 3.5173729e-01 3.2255903e-02 2.0958991e-01]\n",
      " [7.9043537e-02 1.0802548e-04 1.7758565e-01 5.3537340e-04 7.4272734e-01]\n",
      " [3.6448956e-02 3.2949399e-03 9.5901537e-01 2.5676782e-05 1.2150351e-03]\n",
      " [3.0859115e-03 4.3872508e-04 1.2599690e-01 1.8379205e-03 8.6864060e-01]\n",
      " [1.7793437e-07 7.3853874e-07 2.5342579e-06 9.9999619e-01 3.4595112e-07]\n",
      " [2.5060678e-01 7.0500278e-01 4.1326419e-02 2.1839018e-04 2.8455905e-03]\n",
      " [2.6846834e-04 7.1689494e-05 2.1907852e-03 9.9591404e-01 1.5549882e-03]\n",
      " [2.6703227e-01 6.7155123e-01 3.2111373e-02 3.0504141e-03 2.6254687e-02]]\n",
      "most likely model\n",
      "fbm\n",
      "fbm\n",
      "fbm\n",
      "sbm\n",
      "fbm\n",
      "sbm\n",
      "lw\n",
      "ctrw\n",
      "lw\n",
      "ctrw\n",
      "Ground truth\n",
      "lw\n",
      "fbm\n",
      "fbm\n",
      "sbm\n",
      "sbm\n",
      "fbm\n",
      "attm\n",
      "fbm\n",
      "lw\n",
      "fbm\n"
     ]
    }
   ],
   "source": [
    "print(\"probability of each model class for second segment\",'\\n',cl2_3d)\n",
    "print(\"most likely model\")\n",
    "models = ['attm', 'ctrw', 'fbm', 'lw', 'sbm'] \n",
    "for i in range(len(data)):\n",
    "    print(models[np.argmax(cl2_3d[i])])\n",
    "print('Ground truth')    \n",
    "for i in range(len(data)):\n",
    "    print(models[int(Y3[2][i,2])])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
