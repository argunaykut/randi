{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import scipy.io as sci\n",
    "import andi \n",
    "AD = andi.andi_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Generating data for training neural network for inference #########\n",
    "'''\n",
    "Define dimension, number of trajectories for each dataset, trajectory length and number of datasets to be generated\n",
    "'''\n",
    "dimension = 1                # 1, 2 or 3 Dimensions\n",
    "N = 100000                   # Number of trajectories per datasets\n",
    "traj_length = 200            # Length of the trajectories\n",
    "number_dataset = 30          # Number of datasets to be saved\n",
    "\n",
    "n=0\n",
    "for repeat in range(number_dataset): \n",
    "    NA, NA, NA, NA, X, Y = AD.andi_dataset(N = N, tasks = 3, dimensions = dimension, max_T = traj_length,)\n",
    "    sci.savemat(r'data\\segmentation\\ ' + str(dimension) + 'D_' + str(traj_length) + '_' + str(n) + '.mat',{'X': X, 'Y':Y})\n",
    "    n += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Building the recurrent neural networks #####\n",
    "\n",
    "block_size = 2*dimension                                   # Size of the blocks of data points\n",
    "\n",
    "###### Building the recurrent neural network for inference #####\n",
    "model_segmentation_inf = Sequential()\n",
    "\n",
    "model_segmentation_inf.add(LSTM(250,                       # first layer: LSTM of dimension 250\n",
    "                         return_sequences=True,            # return sequences for the second LSTM layer            \n",
    "                         recurrent_dropout=0.2,            # recurrent dropout for preventing overtraining\n",
    "                         input_shape=(None, block_size)))  # input shape\n",
    "                                                           \n",
    "model_segmentation_inf.add(LSTM(50,                          # second layer: LSTM of dimension 50\n",
    "                        dropout=0,\n",
    "                        recurrent_dropout=0.2))\n",
    "\n",
    "model_segmentation_inf.add(Dense(20))                        # dense layer \n",
    "\n",
    "model_segmentation_inf.add(Dense(4))                         # output layer                             \n",
    "\n",
    "model_segmentation_inf.compile(optimizer='adam',\n",
    "                               loss='mse', \n",
    "                               metrics=['mae'])\n",
    "\n",
    "model_segmentation_inf.summary()                             # Printing a summary of the built network\n",
    "\n",
    "\n",
    "###### Building the recurrent neural network for classifying the first model #####\n",
    "model_segmentation_c1 = (Sequential())\n",
    "\n",
    "model_segmentation_c1.add(LSTM(250,                       # first layer: LSTM of dimension 250\n",
    "                         return_sequences=True,            # return sequences for the second LSTM layer            \n",
    "                         recurrent_dropout=0.2,            # recurrent dropout for preventing overtraining\n",
    "                         input_shape=(None, block_size)))  # input shape\n",
    "\n",
    "model_segmentation_c1.add(LSTM(50,                          # second layer: LSTM of dimension 50\n",
    "                        dropout=0,\n",
    "                        recurrent_dropout=0.2))\n",
    "\n",
    "model_segmentation_c1.add(Dense(20))                        # dense layer \n",
    "\n",
    "model_segmentation_c1.add(Dense(5,                         # output layer\n",
    "                                activation=\"softmax\",))\n",
    "\n",
    "model_segmentation_c1.compile(optimizer='adam',\n",
    "                              loss=\"categorical_crossentropy\",\n",
    "                              metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "model_segmentation_c1.summary()                             # Printing a summary of the built network\n",
    "\n",
    "\n",
    "\n",
    "###### Building the recurrent neural network for classifying the second model #####\n",
    "model_segmentation_c2 = Sequential()\n",
    "\n",
    "model_segmentation_c2.add(LSTM(250,                       # first layer: LSTM of dimension 250\n",
    "                         return_sequences=True,            # return sequences for the second LSTM layer            \n",
    "                         recurrent_dropout=0.2,            # recurrent dropout for preventing overtraining\n",
    "                         input_shape=(None, block_size)))  # input shape\n",
    "                                                           \n",
    "model_segmentation_c2.add(LSTM(50,                          # second layer: LSTM of dimension 50\n",
    "                        dropout=0,\n",
    "                        recurrent_dropout=0.2))\n",
    "\n",
    "model_segmentation_c2.add(Dense(20))                        # dense layer \n",
    "\n",
    "model_segmentation_c2.add(Dense(5,                          # output layer\n",
    "                                activation=\"softmax\",))\n",
    "\n",
    "model_segmentation_c2.compile(optimizer='adam',\n",
    "                              loss=\"categorical_crossentropy\",\n",
    "                              metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "model_segmentation_c2.summary()                             # Printing a summary of the built network'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Define the function for preprocessing the data #######\n",
    "\n",
    "def data_prepare(X,Y,N,traj_length,dimension):                # regularize trajectories for training\n",
    "    import numpy as np \n",
    "    thr=1e-10\n",
    "    r = np.array(X).reshape(N,dimension,traj_length)              \n",
    "    r = np.diff(r,axis=2)\n",
    "    x = np.zeros((N,0))\n",
    "    for dim in range(dimension):\n",
    "        y = r[:,dim,:]\n",
    "        sy = np.std(y,axis=1)\n",
    "        y = (y-np.mean(y,axis=1).reshape(len(y),1)) / np.where(sy>thr,sy,1).reshape(len(y),1)   # normalize x data\n",
    "        y = np.concatenate((y,np.zeros((N,1))),axis=1)\n",
    "        x = np.concatenate((x,y),axis=1)                   # merge dimensions\n",
    "    x = np.transpose(x.reshape(N,dimension,traj_length),axes = [0,2,1])\n",
    "        \n",
    "            \n",
    "    label_inf=np.zeros((N,4))\n",
    "    label_inf[:,0]=Y[:,3]                               # the first exponent\n",
    "    label_inf[:,1]=Y[:,5]                               # the second exponent\n",
    "    label_inf[:,2]=np.sin((2*np.pi*Y[:,1])/traj_length) # sine of the switching time\n",
    "    label_inf[:,3]=np.cos((2*np.pi*Y[:,1])/traj_length) # cosine of the switching time\n",
    "    \n",
    "    label_c1 = []\n",
    "    label_c1.append(np.equal(Y[:,2],0))                # if the first model is attm\n",
    "    label_c1.append(np.equal(Y[:,2],1))                # if the first model is ctrw\n",
    "    label_c1.append(np.equal(Y[:,2],2))                # if the first model is sbm\n",
    "    label_c1.append(np.equal(Y[:,2],3))                # if the first model is lw\n",
    "    label_c1.append(np.equal(Y[:,2],4))                # if the first model is fbm\n",
    "    label_c1 = np.array(np.transpose(label_c1)) + 0                            \n",
    "\n",
    "    label_c2 = []\n",
    "    label_c2.append(np.equal(Y[:,4],0))                # if the second model is attm\n",
    "    label_c2.append(np.equal(Y[:,4],1))                # if the second model is ctrw\n",
    "    label_c2.append(np.equal(Y[:,4],2))                # if the second model is sbm\n",
    "    label_c2.append(np.equal(Y[:,4],3))                # if the second model is lw\n",
    "    label_c2.append(np.equal(Y[:,4],4))                # if the second model is fbm\n",
    "    label_c2 = np.array(np.transpose(label_c2)) + 0                            \n",
    "    \n",
    "    return(x, label_inf, label_c1, label_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Training the recurrent neural networks #####\n",
    "\n",
    "batch_sizes = [32, 128, 512, 2048]\n",
    "dataset_used = [1, 4, 5, 20]\n",
    "number_epochs = [5, 4, 3, 2]\n",
    "\n",
    "n = 0\n",
    "for batch in range(len(batch_sizes)):    \n",
    "    for repeat in range(dataset_used[batch]):\n",
    "        data = sci.loadmat(r'data\\segmentation\\ ' + str(dimension) + 'D_' + str(traj_length) + '_' + str(n) + '.mat')\n",
    "        n += 1\n",
    "        X = data['X'][0][dimension-1]\n",
    "        Y = data['Y'][0][dimension-1].reshape(N,6)\n",
    "        x, label_inf, label_c1, label_c2 = data_prepare(X,Y,N,traj_length,dimension)\n",
    "        \n",
    "        model_segmentation_inf.fit(x.reshape(N,int(dimension*traj_length/block_size),block_size),\n",
    "                                 label_inf, \n",
    "                                 epochs=number_epochs[batch], \n",
    "                                 batch_size=batch_sizes[batch],\n",
    "                                 validation_split=0.1,\n",
    "                                 shuffle=True)\n",
    "        \n",
    "        model_segmentation_c1.fit(x.reshape(N,int(dimension*traj_length/block_size),block_size),\n",
    "                                 label_c1, \n",
    "                                 epochs=number_epochs[batch], \n",
    "                                 batch_size=batch_sizes[batch],\n",
    "                                 validation_split=0.1,\n",
    "                                 shuffle=True)\n",
    "\n",
    "        model_segmentation_c2.fit(x.reshape(N,int(dimension*traj_length/block_size),block_size),\n",
    "                                 label_c2, \n",
    "                                 epochs=number_epochs[batch], \n",
    "                                 batch_size=batch_sizes[batch],\n",
    "                                 validation_split=0.1,\n",
    "                                 shuffle=True)\n",
    "\n",
    "model_segmentation_inf.save('nets\\user_trained\\segmentation_inf_' + str(traj_length) + '.h5')     # Save the network \n",
    "model_segmentation_c1.save('nets\\user_trained\\segmentation_c1_' + str(traj_length) + '.h5')     # Save the network \n",
    "model_segmentation_c2.save('nets\\user_trained\\segmentation_c2_' + str(traj_length) + '.h5')     # Save the network "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
