{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import andi\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses, metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "#from keras.models import load_model\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "#from data_split import data_split\n",
    "from utils import data_norm, data_reshape, many_net_uhd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example file we saw how to use the networks for trajectories of equal length. Now let's see how to use them for trajectories of different lengths as the ones provided in the AnDi Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the data from the AnDi Challenge at https://andi-app.herokuapp.com/andi_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trajs_from_files = csv.reader(open('challenge_for_scoring/task1.txt','r'), delimiter=';', \n",
    "                                        lineterminator='\\n',quoting=csv.QUOTE_NONNUMERIC)\n",
    "validation = [[],[],[]]\n",
    "for trajs in enumerate(trajs_from_files):\n",
    "    validation[int(trajs[1][0])-1].append(trajs[1][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the inference networks is the inferred anomalous exponent for each trajectory. Trajectories must be of equal length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the networks used for inference in 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_inf_1d = [25, 50, 65, 75, 125, 165, 225, \n",
    "                  325, 425, 525, 625, 725, 825, 925]\n",
    "\n",
    "meta_model_inf_1d = []\n",
    "for i in centers_inf_1d: \n",
    "    m = load_model('nets/inference_nets/1d/inference_1D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_inf_1d.append(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the block size required by each net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in meta_model_inf_1d:\n",
    "        print(n.layers[0].input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_set = validation[0]\n",
    "tot_tt=len(traj_set)\n",
    "count=0\n",
    "pred_inf_1d = []\n",
    "for traj in traj_set:\n",
    "    count=count+1\n",
    "    aa = np.asarray(traj).reshape(1,-1)\n",
    "    pr = many_net_uhd(nets = meta_model_inf_1d, traj_set = aa, centers = centers_inf_1d ,dim = 1, task =1)\n",
    "   # print(pr)\n",
    "    pred_inf_1d.append(pr.flatten())\n",
    "    print('traj',count,'/',tot_tt,end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference in 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_inf_2d = [25, 65, 125, 225, 325, 425, 525, 725, 925]\n",
    "meta_model_inf_2d = []\n",
    "for i in centers_inf_2d: \n",
    "    m = load_model('nets/inference_nets/2d/inference_2D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_inf_2d.append(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_set = validation[1]\n",
    "tot_tt=len(traj_set)\n",
    "count=0\n",
    "pred_inf_2d = []\n",
    "for traj in traj_set:\n",
    "    count=count+1\n",
    "    aa = np.asarray(traj).reshape(1,-1)\n",
    "    pr = many_net_uhd(nets = meta_model_inf_2d, traj_set = aa, centers = centers_inf_2d ,dim = 2, task =1)\n",
    "   # print(pr)\n",
    "    pred_inf_2d.append(pr.flatten())\n",
    "    print('traj',count,'/',tot_tt,end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_inf_3d = [25, 65, 125, 225, 525, 925]\n",
    "meta_model_inf_3d = []\n",
    "for i in centers_inf_3d: \n",
    "    m = load_model('nets/inference_nets/3d/inference_3D_'+str(i)+'.h5')\n",
    "    \n",
    "    meta_model_inf_3d.append(m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_set = validation[2]\n",
    "tot_tt=len(traj_set)\n",
    "count=0\n",
    "pred_inf_3d = []\n",
    "for traj in traj_set:\n",
    "    count=count+1\n",
    "    aa = np.asarray(traj).reshape(1,-1)\n",
    "    pr = many_net_uhd(nets = meta_model_inf_3d, traj_set = aa, centers = centers_inf_3d ,dim = 3, task =1)\n",
    "   # print(pr)\n",
    "    pred_inf_3d.append(pr.flatten())\n",
    "    print('traj',count,'/',tot_tt,end='\\r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
